# vector_store.py
import json
import os
from langchain_community.vectorstores import Chroma
#from langchain_openai import OpenAIEmbeddings
from langchain_upstage import UpstageEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_text_splitters import RecursiveJsonSplitter
from langchain.docstore.document import Document
from . import config
from dotenv import load_dotenv

# Using built-in sqlite3 instead of pysqlite3 to avoid import issues
import sqlite3

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

class VectorStoreManager:
    """
    ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ ë²¡í„° DBë¥¼ êµ¬ì¶•í•˜ê³  ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤.
    """
    def __init__(self, persist_directory=config.CHROMA_DB_PATH):
        self.persist_directory = persist_directory
        self.doc_embedding = UpstageEmbeddings(
            api_key=api_key,
            model="solar-embedding-1-large-passage"
)
        self.query_embedding = UpstageEmbeddings(
            api_key=api_key,
            model="solar-embedding-1-large-query"
)

    
    def _load_documents_from_json(self, json_path):
        if not os.path.exists(json_path):
            print(f"WARNING: '{json_path}' íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return []
            
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        documents = []
        for item in data:
            # combined_textë¥¼ ì£¼ ë‚´ìš©ìœ¼ë¡œ, ë‚˜ë¨¸ì§€ë¥¼ ë©”íƒ€ë°ì´í„°ë¡œ ì €ì¥
            metadata = {
                'id': item.get('id', ''),
                'title': item.get('title', ''),
                'ingredients': item.get('ingredients', ''),
                'url': item.get('url', '')
            }
            doc = Document(page_content=item.get('combined_text', ''), metadata=metadata)
            documents.append(doc)
        return documents

    def build(self, json_path=config.MERGED_PREPROCESSED_FILE):
        print("INFO: ë²¡í„° DB êµ¬ì¶•ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        if not os.path.exists(json_path):
            print(f"ERROR: '{json_path}' íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return None

        with open(json_path, 'r', encoding='utf-8') as file:
            data = json.load(file)
        
        documents = []
        for item in data:
            metadata = {
                'id': item.get('id', ''),
                'title': item.get('title', ''),
                'ingredients': item.get('ingredients', ''),
                'url': item.get('url', '')
            }
            doc = Document(page_content=item.get('combined_text', ''), metadata=metadata)
            documents.append(doc)
        
        print(f"INFO: ì´ {len(data)}ê°œì˜ ë¬¸ì„œë¥¼ {len(documents)}ê°œì˜ ì²­í¬ë¡œ ë¶„í• í–ˆìŠµë‹ˆë‹¤.")
        
        # Chroma ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶•
        print("INFO: 'passage' ëª¨ë¸ë¡œ ë¬¸ì„œ ì„ë² ë”© ë° DB ì €ì¥ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
        vectorstore = Chroma.from_documents(
            documents=documents,
            embedding=self.doc_embedding,
            persist_directory=self.persist_directory
        )
        print(f"SUCCESS: ë²¡í„° DB êµ¬ì¶• ì™„ë£Œ. '{self.persist_directory}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return vectorstore
        
    def load(self):
        if not os.path.exists(self.persist_directory):
            print("ERROR: ì €ì¥ëœ ë²¡í„° DBê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € DBë¥¼ êµ¬ì¶•í•´ì•¼ í•©ë‹ˆë‹¤.")
            return None
            
        # --- ìˆ˜ì •: DB ë¡œë“œ(ì¿¼ë¦¬) ì‹œì—ëŠ” 'query' ì§ˆë¬¸ìš© ì„ë² ë”© ëª¨ë¸ ì‚¬ìš© ---
        print("INFO: ê¸°ì¡´ ë²¡í„° DBë¥¼ 'query' ëª¨ë¸ë¡œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤...")
        vectorstore = Chroma(
            persist_directory=self.persist_directory,
            embedding_function=self.query_embedding # ğŸ‘ˆ ì§ˆë¬¸ìš© ëª¨ë¸ ì‚¬ìš©
        )
        return vectorstore